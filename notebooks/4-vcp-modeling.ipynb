{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "* [Modeling](#modeling)\n",
    "    - [Prepare data](#prepare)\n",
    "    - [Multivariate Adaptative Regression Splines (MARS)](#mars)\n",
    "    - [K-Nearest Neighbohrs (KNN)](#knn)\n",
    "    - [Suppor Vector Machines (SVM)](#svm)\n",
    "    - [Random Forests](#RF)\n",
    "    - [Artificial Neural Network (ANN)](#ann)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Common libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "from yellowbrick.regressor import ResidualsPlot, PredictionError\n",
    "from yellowbrick.model_selection import ValidationCurve, LearningCurve, CVScores\n",
    "\n",
    "# Graphics\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import plotly as pty\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline=True)\n",
    "\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "<a id=\"modeling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from wind_power_forecasting.nodes import metric\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model as lm\n",
    "from pyearth import Earth\n",
    "from sklearn.model_selection import TimeSeriesSplit,  cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import plotly.graph_objects as go\n",
    "from sklearn import linear_model, datasets\n",
    "import scipy as sp\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow import log_metric, log_param, log_artifact\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from operational_analysis.toolkits import filters\n",
    "from operational_analysis.toolkits import power_curve\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "<a id=\"prepare\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = context.catalog.load(\"X_train_raw\")\n",
    "X_train_raw[\"Time\"] = pd.to_datetime(X_train_raw[\"Time\"], format=\"%d/%m/%Y %H:%M\")\n",
    "y_train_raw = context.catalog.load(\"y_train_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_raw = context.catalog.load(\"X_test_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows by WF\n",
    "df = X_train_raw[X_train_raw['WF'] == 'WF6']\n",
    "\n",
    "# Join X and y just to split in X_train and y_train later on in one shot.\n",
    "df = pd.merge(df, y_train_raw, on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Production'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split X in train and test sets\n",
    "\n",
    "def split_data_by_date(date, X, y):\n",
    "    \"\"\"\n",
    "    It splits X and y sets by a 'Time' value \n",
    "    into sets for training and testing. \n",
    "        - Return: a dictionary with the four sets\n",
    "                  (X_train, y_train, X_test, y_test)\n",
    "    \"\"\"\n",
    "    sets = {}\n",
    "    date_cut = dt.datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    X_test = X[X['Time'] > date_cut]\n",
    "    X_train = X[X['Time'] <= date_cut]\n",
    "    y_train = y[X_train.index]\n",
    "    y_test = y[X_test.index]\n",
    "    \n",
    "    sets['X_train'] = X_train\n",
    "    sets['X_test'] = X_test\n",
    "    sets['y_train'] = y_train\n",
    "    sets['y_test'] = y_test\n",
    "    \n",
    "    return sets\n",
    "\n",
    "train_test_dfs = split_data_by_date('2018-11-13 23:00:00', df, df['Production'])\n",
    "X_train = train_test_dfs.get('X_train')\n",
    "X_test = train_test_dfs.get('X_test')\n",
    "y_train = train_test_dfs.get('y_train')\n",
    "y_test = train_test_dfs.get('y_test')\n",
    "\n",
    "del X_train['Production']\n",
    "del X_test['Production']\n",
    "\n",
    "# For predictions only can be used data avialable on day D at 09h. --> columns 3 to -9 \n",
    "X_test = X_test[X_test.columns[0:-9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wind_power_forecasting.nodes import data_transformation as dtr\n",
    "## Input missing values #####\n",
    "new_cols = ['NWP1_U','NWP1_V','NWP1_T','NWP2_U',\n",
    "            'NWP2_V','NWP3_U','NWP3_V','NWP3_T',\n",
    "            'NWP4_U','NWP4_V','NWP4_CLCT']\n",
    "        \n",
    "dtr.add_new_cols(new_cols, X_train)\n",
    "dtr.add_new_cols(new_cols, X_test)\n",
    "\n",
    "# Missing values inputation based on previous observations\n",
    "cols_train = X_train_raw.columns[3:]\n",
    "cols_test = X_train_raw.columns[3:-9]\n",
    "X_train = dtr.input_missing_values(X_train, cols_train)\n",
    "X_test = dtr.input_missing_values(X_test, cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing values inputation with interpolation (missings due to the provision frequency of each NWP)\n",
    "\n",
    "col_list = ['NWP2_U','NWP2_V','NWP3_U','NWP3_V','NWP3_T']\n",
    "X_train.index = X_train['Time']\n",
    "\n",
    "del X_train['Time']\n",
    "    \n",
    "for var in col_list:\n",
    "    X_train[var].interpolate(\n",
    "        method='time', \n",
    "        inplace=True,\n",
    "        limit=2,\n",
    "        limit_direction='both'\n",
    "    )\n",
    "X_train.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "X_test.index = X_test['Time']\n",
    "del X_test['Time']\n",
    "    \n",
    "for var in col_list:\n",
    "    X_test[var].interpolate(\n",
    "        method='time', \n",
    "        inplace=True,\n",
    "        limit=2,\n",
    "        limit_direction='both'\n",
    "    )\n",
    "X_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the best data for each weather feature\n",
    "X_train[\"U\"] = X_train.NWP2_U\n",
    "X_train[\"V\"] = X_train.NWP1_V\n",
    "X_train[\"T\"] = X_train.NWP3_T \n",
    "X_train[\"CLCT\"] = X_train.NWP4_CLCT\n",
    "\n",
    "X_train = X_train[['ID','Time','U','V','T','CLCT']]\n",
    "\n",
    "####\n",
    "X_test[\"U\"] = X_test.NWP2_U\n",
    "X_test[\"V\"] = X_test.NWP1_V\n",
    "X_test[\"T\"] = X_test.NWP3_T \n",
    "X_test[\"CLCT\"] = X_test.NWP4_CLCT\n",
    "\n",
    "X_test = X_test[['ID','Time','U','V','T','CLCT']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flagged_pc(ws, p, flag_bool, alpha):\n",
    "    plt.scatter(ws, p, s = 3, alpha = alpha)\n",
    "    plt.scatter(ws[flag_bool], p[flag_bool], s = 3, c = 'red')\n",
    "    plt.xlabel('Wind speed (m/s)')\n",
    "    plt.ylabel('Power (MWh)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####### Cleaning outliers in X_train ########\n",
    "clean_outliers = True\n",
    "\n",
    "if clean_outliers:\n",
    "    # Power curve data\n",
    "    X_train['Production'] = y_train.to_list()\n",
    "    X_train['vel'] = X_train.apply(dtr._get_wind_speed, axis=1)\n",
    "    X_train_ = X_train[['vel','Production']]\n",
    "    \n",
    "    # top-curve stacked outliers\n",
    "    top_stacked = filters.window_range_flag(\n",
    "        X_train_.Production, 0.70*X_train_.Production.max(), X_train_.Production.max(), X_train_.vel, 12.5, 2000.)\n",
    "\n",
    "    # sparse outliers\n",
    "    max_bin = 0.99*X_train_.Production.max()\n",
    "    sparse_outliers = filters.bin_filter(\n",
    "        X_train_.Production, X_train_.vel, 0.05, 0.8*X_train_.vel.std(), 'median', 0.025, max_bin, 'scalar', 'all')\n",
    "\n",
    "    # bottom-curve stacked outliers\n",
    "    bottom_stacked = filters.window_range_flag(X_train_.vel, 7.5, 40, X_train_.Production, 0.03, 2000.)\n",
    "    \n",
    "    outliers = {}\n",
    "    outliers['bottom'] = bottom_stacked\n",
    "    outliers['sparse'] = sparse_outliers\n",
    "    outliers['top'] = top_stacked\n",
    "    \n",
    "    plot_flagged_pc(X_train_.vel, X_train_.Production,(top_stacked) | (sparse_outliers) | (bottom_stacked), 0.3)\n",
    "       \n",
    "    # Remove outliers\n",
    "    for value in outliers.values():\n",
    "        X_train_.vel = X_train_.vel[(~value)]\n",
    "        X_train_.Production = X_train.Production[(~value)]\n",
    "\n",
    "    # select no-outliers observations\n",
    "    X_train = X_train.loc[X_train[\"vel\"].isin(X_train_.vel)]\n",
    "    y_train = X_train[\"Production\"]\n",
    "\n",
    "    del X_train[\"Production\"], X_train[\"vel\"], X_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FiX_train abnormal values in CLCT\n",
    "X_train.loc[X_train['CLCT'] < 0, 'CLCT'] = 0.\n",
    "X_test.loc[X_test['CLCT'] < 0, 'CLCT'] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    cape = metric.get_cape(actual, pred)\n",
    "    return rmse, mae, r2, cape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train.copy()\n",
    "X_test_2 = X_test.copy()\n",
    "y_train_2 = y_train.copy()\n",
    "y_test_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Adaptative Regression Splines (MARS)\n",
    "<a id=\"mars\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for k_best in range(1,4):\n",
    "    # print('------- k_best_features = {} ----------'.format(k_best))\n",
    "    \n",
    "## Feature engineering pipeline #####\n",
    "feat_adder = dtr.NewFeaturesAdder(add_time_feat=True, add_cycl_feat=True, add_inv_T=False, add_interactions=True)\n",
    "\n",
    "drop_lst = []\n",
    "if feat_adder.get_params().get('add_cycl_feat'):\n",
    "    if feat_adder.get_params().get('add_inv_T'):\n",
    "        drop_lst = [\"ID\", \"Time\", \"U\", \"V\", \"wdir\", \"hour\", \"month\", \"T\"]\n",
    "    else:\n",
    "        drop_lst = [\"ID\", \"Time\", \"U\", \"V\", \"wdir\", \"hour\", \"month\"]\n",
    "else:\n",
    "    if feat_adder.get_params().get('add_inv_T'):\n",
    "        drop_lst = [\"ID\", \"Time\", \"U\", \"V\", \"T\"]\n",
    "    else:\n",
    "        drop_lst = [\"ID\", \"Time\", \"U\", \"V\"]\n",
    "\n",
    "pre_process = ColumnTransformer(remainder = 'passthrough',\n",
    "                                transformers = [(\n",
    "                                    'drop_columns', 'drop', drop_lst)\n",
    "                                ])\n",
    "\n",
    "# transforming target because of its skweed distribution.\n",
    "# tt = Pipeline(steps=[\n",
    "#    ('powertransformer', PowerTransformer(method='yeo-johnson', standardize=True)), \n",
    "# ])\n",
    "\n",
    "feat_eng_pipeline = Pipeline(steps=[\n",
    "    ('attr_adder', feat_adder), \n",
    "    ('pre_processing', pre_process),  \n",
    "])\n",
    "\n",
    "\n",
    "X_train_pped = feat_eng_pipeline.fit_transform(X_train_2)\n",
    "X_test_pped = feat_eng_pipeline.transform(X_test_2)\n",
    "\n",
    "\n",
    "#### \n",
    "# Feature selection\n",
    "feature_names = X_train_2.drop(drop_lst, axis=1).columns\n",
    "selec_k_best = SelectKBest(mutual_info_regression, k=1)        \n",
    "\n",
    "# make scorers\n",
    "cape_scorer = make_scorer(metric.get_cape, greater_is_better=False)\n",
    "\n",
    "## Modeling: MARS using py-earth ######\n",
    "# mars = TransformedTargetRegressor(\n",
    "#     Earth(feature_importance_type='gcv'),\n",
    "#     transformer=PowerTransformer(method=\"yeo-johnson\"),\n",
    "#     check_inverse=True\n",
    "# )\n",
    "mars = Earth(feature_importance_type='gcv')\n",
    "\n",
    "pipeline = Pipeline([('powertransformer', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
    "                      (\"univariate_sel\", selec_k_best), \n",
    "                      (\"mars\", mars)])\n",
    "\n",
    "\n",
    "#param_grid = {'mars__regressor__max_degree': [3,4,5], \n",
    "#              'mars__regressor__allow_linear': [False, True], \n",
    "#              'mars__regressor__penalty': [0.,1.,2.,3.,4.,5.,6.],\n",
    "#              'univariate_sel__k': list(range(1,3)),\n",
    "#              }\n",
    "\n",
    "param_grid = {'mars__max_degree': [3,4,5], \n",
    "              'mars__allow_linear': [False, True], \n",
    "              'mars__penalty': [0.,1.,2.,3.,4.,5.,6.],# \n",
    "              'univariate_sel__k': list(range(1,6)),\n",
    "              }\n",
    "\n",
    "# Cross validation and hyper-parameter tunning with grid seach\n",
    "scoring = {'RMSE': 'neg_root_mean_squared_error', 'MAE': 'neg_mean_absolute_error', 'R2':'r2' , 'CAPE': cape_scorer}\n",
    "n_splits = 7\n",
    "tscv = TimeSeriesSplit(n_splits)\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid, \n",
    "    cv=tscv,\n",
    "    scoring=scoring, \n",
    "    refit='CAPE',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_pped, y_train_2)\n",
    "\n",
    "best_mars = grid_search.best_estimator_\n",
    "\n",
    "experiment_name = 'WF1: MARS'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Feature selection with the best k value obtanined in Grid Search\n",
    "    selec_k_best = SelectKBest(mutual_info_regression, k=grid_search.best_params_['univariate_sel__k'])\n",
    "    selec_k_best.fit(X_train_pped, y_train_2)\n",
    "    \n",
    "    mask =selec_k_best.get_support() #list of booleans\n",
    "    selected_feat = [] \n",
    "\n",
    "    for bool, feature in zip(mask, feature_names):\n",
    "        if bool:\n",
    "            selected_feat.append(feature)  \n",
    "\n",
    "\n",
    "    # predicting on test data\n",
    "    predictions = best_mars.predict(X_test_pped)\n",
    "\n",
    "    # build prediction matrix (ID,Production)\n",
    "    pred_matrix = np.stack((np.array(y_test_2.index.to_series()).astype(int), predictions), axis=-1)\n",
    "    df_pred = pd.DataFrame(data=pred_matrix.reshape(-1,2), columns=['ID','Production'])\n",
    "    \n",
    "    # fix negative values in target predictions\n",
    "    df_pred.loc[df_pred['Production'] < 0, 'Production'] = 0.0\n",
    "\n",
    "    # print score\n",
    "    results = grid_search.cv_results_\n",
    "    for scorer in sorted(scoring):\n",
    "        best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
    "        best_CV = results['mean_test_%s' % scorer][best_index]\n",
    "        best_CV_std = results['std_test_%s' % scorer][best_index]\n",
    "        \n",
    "        if (scorer=='RMSE') or (scorer=='MAE') or (scorer=='CAPE'):\n",
    "            print('Best CV {0}:{1:.2f}, std:{2:.2f}'.format(scorer,-best_CV,best_CV_std))\n",
    "        else:\n",
    "            print('Best CV {0}:{1:.2f}, std:{2:.2f}'.format(scorer,best_CV,best_CV_std))           \n",
    "     \n",
    "    print('Test CAPE: ', metric.get_cape(y_test_2, predictions))\n",
    "    print('Test R2: ', r2_score(y_test_2, predictions))\n",
    "    print('Test rmse: ', np.sqrt(mean_squared_error(y_test_2, predictions)))\n",
    "\n",
    "    ### MLFlow logging ####\n",
    "    (rmse, mae, r2, cape) = eval_metrics(y_test_2, predictions)\n",
    "    mlflow.set_tag(\"grid_searh_best_params\", grid_search.best_params_)\n",
    "\n",
    "    # pre-processing\n",
    "    mlflow.log_param(\"clean_outliers\", clean_outliers)\n",
    "    mlflow.log_param(\"selected_features\", selected_feat)\n",
    "    mlflow.log_param(\"k_best_features\", best_mars.get_params().get(\"univariate_sel__k\"))\n",
    "\n",
    "    # grid search parameters\n",
    "    mlflow.log_param(\"max_degree\", best_mars.get_params().get(\"mars__max_degree\"))\n",
    "    mlflow.log_param(\"penalty\", best_mars.get_params().get(\"mars__penalty\"))\n",
    "    mlflow.log_param(\"allow_linear\", best_mars.get_params().get(\"mars__allow_linear\"))\n",
    "    mlflow.log_param(\"CV_splits\", n_splits)\n",
    "\n",
    "    # metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"cape\", cape)\n",
    "\n",
    "    # artifacts\n",
    "    mlflow.sklearn.log_model(mars, \"mars\")\n",
    "    # mlflow.log_artifact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.get_params().get(\"mars\")\n",
    "cv = TimeSeriesSplit(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz = ValidationCurve(\n",
    "    model,\n",
    "    param_name=\"max_terms\",\n",
    "    param_range=np.arange(1, 500, 10),\n",
    "    cv=cv,\n",
    "    scoring=\"r2\",\n",
    ")\n",
    "\n",
    "viz.fit(X_train_pped, y_train_2)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curves\n",
    "visualizer = LearningCurve(\n",
    "    model, cv=cv, scoring=\"r2\", train_sizes=np.linspace(0.1, 1.0, 10)\n",
    ")\n",
    "visualizer.fit(X_train_pped, y_train_2)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cross validation scores.\n",
    "vi = CVScores(\n",
    "    model,\n",
    "    cv=cv,\n",
    "    scoring=scorer,\n",
    ")\n",
    "vis.fit(X_train_pped, y_train_2)\n",
    "vis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K - Nearest Neighbohrs (KNN)\n",
    "<a id=\"knn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train.copy()\n",
    "X_test_2 = X_test.copy()\n",
    "y_train_2 = y_train.copy()\n",
    "y_test_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "## Feature engineering pipeline #####\n",
    "feat_adder = dtr.NewFeaturesAdder(add_time_feat=False, add_cycl_feat=False, add_inv_T=False, add_interactions=True)\n",
    "\n",
    "drop_lst = []\n",
    "if feat_adder.get_params().get('add_cycl_feat'):\n",
    "    if feat_adder.get_params().get('add_inv_T'):\n",
    "        drop_lst = [\"ID\", \"Time\", \"U\", \"V\", \"wdir\", \"hour\", \"month\", \"T\"]\n",
    "    else:\n",
    "        drop_lst = [\"ID\", \"Time\", \"U\", \"V\", \"wdir\", \"hour\", \"month\"]\n",
    "else:\n",
    "    if feat_adder.get_params().get('add_inv_T'):\n",
    "        drop_lst = [\"ID\", \"Time\", \"U\", \"V\", \"T\"]\n",
    "    else:\n",
    "        drop_lst = [\"ID\", \"Time\", \"U\", \"V\"]\n",
    "\n",
    "pre_process = ColumnTransformer(remainder = 'passthrough',\n",
    "                                transformers = [(\n",
    "                                    'drop_columns', 'drop', drop_lst)\n",
    "                                ])\n",
    "\n",
    "# transforming target because of its skweed distribution.\n",
    "tt = Pipeline(steps=[\n",
    "    ('powertransformer', PowerTransformer(method='yeo-johnson', standardize=True)), \n",
    "])\n",
    "\n",
    "feat_eng_pipeline = Pipeline(steps=[\n",
    "    ('attr_adder', feat_adder), \n",
    "    ('pre_processing', pre_process), \n",
    "])\n",
    "\n",
    "\n",
    "X_train_pped = feat_eng_pipeline.fit_transform(X_train_2)\n",
    "X_test_pped = feat_eng_pipeline.transform(X_test_2)\n",
    "\n",
    "#### \n",
    "# Feature selection\n",
    "feature_names = X_train_2.drop(drop_lst, axis=1).columns\n",
    "selec_k_best = SelectKBest(mutual_info_regression, k=1)        \n",
    "\n",
    "# make scorers\n",
    "cape_scorer = make_scorer(metric.get_cape, greater_is_better=False)\n",
    "\n",
    "knn_reg = KNeighborsRegressor()\n",
    "\n",
    "pipeline = Pipeline([('powertransformer', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
    "                     (\"univariate_sel\", selec_k_best), (\"knn\", knn_reg)])\n",
    "\n",
    "# KNN model\n",
    "#param_grid = {\n",
    "#    'knn__regressor__n_neighbors': list(range(1,50,2)),\n",
    "#    'knn__regressor__algorithm':['auto', 'kd_tree'],\n",
    "#    'knn__regressor__weights': ['uniform','distance'],\n",
    "#    'knn__regressor__metric': ['cityblock','mahalanobis','euclidean'],\n",
    "#    'knn__regressor__p': [1,2],\n",
    "#    'univariate_sel__k': list(range(1,4))\n",
    "#}\n",
    "#\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': list(range(1,50,2)),\n",
    "    'knn__algorithm':['ball_tree', 'kd_tree'],\n",
    "    'knn__weights': ['uniform','distance'],\n",
    "    'knn__metric': [\"cityblock\", \"euclidean\", \"manhattan\"],\n",
    "    'univariate_sel__k': [3],\n",
    "}\n",
    "\n",
    "n_splits=6\n",
    "tscv = TimeSeriesSplit(n_splits)\n",
    "scoring = {'RMSE': 'neg_root_mean_squared_error', 'MAE': 'neg_mean_absolute_error', 'R2':'r2' , 'CAPE': cape_scorer}\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid, \n",
    "    cv= tscv,\n",
    "    n_jobs=-1,\n",
    "    scoring=scoring,\n",
    "    refit='CAPE'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_pped, y_train_2)\n",
    "\n",
    "experiment_name = 'WF1: KNN'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Feature selection with the best k value obtanined in Grid Search\n",
    "    selec_k_best = SelectKBest(mutual_info_regression, k=grid_search.best_params_['univariate_sel__k'])\n",
    "    selec_k_best.fit(X_train_pped, y_train_2)\n",
    "    \n",
    "    mask =selec_k_best.get_support() #list of booleans\n",
    "    selected_feat = [] \n",
    "\n",
    "    for bool, feature in zip(mask, feature_names):\n",
    "        if bool:\n",
    "            selected_feat.append(feature)  \n",
    "    # Re-train the model with the best parameters found in CV \n",
    "    # knn_reg2 = TransformedTargetRegressor(\n",
    "    #    KNeighborsRegressor(algorithm=grid_search_knn.best_params_['knn__regressor__algorithm'],\n",
    "    #                         n_neighbors=grid_search_knn.best_params_['knn__regressor__n_neighbors'],\n",
    "    #                         p=grid_search_knn.best_params_['knn__regressor__p'], \n",
    "    #                         weights=grid_search_knn.best_params_['knn__regressor__weights'],\n",
    "    #                         metric=grid_search_knn.best_params_['knn__regressor__metric']),\n",
    "    #     transformer=PowerTransformer(method=\"yeo-johnson\", standardize=True), check_inverse=False) \n",
    "        \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_model.fit(X_train_pped, y_train_2)\n",
    "    #knn_reg2.fit(X_train_pped, y_train)\n",
    "\n",
    "    # Testing\n",
    "    predictions = best_model.predict(X_test_pped)\n",
    "\n",
    "    # Building prediction matrix (ID,Production)\n",
    "    pred_matrix = np.stack((np.array(y_test.index.to_series()).astype(int), predictions), axis=-1)\n",
    "    df_pred = pd.DataFrame(data=pred_matrix.reshape(-1,2), columns=['ID','Production'])\n",
    "\n",
    "    # print score\n",
    "    results = grid_search.cv_results_\n",
    "    for scorer in sorted(scoring):\n",
    "        best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
    "        best_CV = results['mean_test_%s' % scorer][best_index]\n",
    "        best_CV_std = results['std_test_%s' % scorer][best_index]\n",
    "        \n",
    "        if (scorer=='RMSE') or (scorer=='MAE') or (scorer=='CAPE'):\n",
    "            print('Best CV {0}:{1:.2f}, std:{2:.2f}'.format(scorer,-best_CV,best_CV_std))\n",
    "        else:\n",
    "            print('Best CV {0}:{1:.2f}, std:{2:.2f}'.format(scorer,best_CV,best_CV_std))           \n",
    "     \n",
    "    print('Test CAPE: ', metric.get_cape(y_test_2, predictions))\n",
    "    print('Test R2: ', r2_score(y_test_2, predictions))\n",
    "    print('Test rmse: ', np.sqrt(mean_squared_error(y_test_2, predictions)))\n",
    "\n",
    "    ### MLFlow logging ####\n",
    "    (rmse, mae, r2, cape) = eval_metrics(y_test_2, predictions)\n",
    "\n",
    "    mlflow.set_tag(\"grid_searh_best_params\", grid_search.best_params_)\n",
    "\n",
    "    # pre-processing\n",
    "    mlflow.log_param(\"clean_outliers\", clean_outliers)\n",
    "    mlflow.log_param(\"selected_features\", selected_feat)\n",
    "    mlflow.log_param(\"k_best_features\", param_grid.get(\"knn__univariate_sel__k\"))\n",
    "\n",
    "    # grid search parameters\n",
    "    mlflow.log_param(\"n_neighbors\", param_grid.get(\"knn__regressor__n_neighbors\"))\n",
    "    mlflow.log_param(\"algorithm\", param_grid.get(\"knn__regressor__algorithm\"))\n",
    "    mlflow.log_param(\"weights\", param_grid.get(\"knn__regressor__weights\"))\n",
    "    mlflow.log_param(\"metric\", param_grid.get(\"knn__regressor__metric\"))\n",
    "    mlflow.log_param(\"CV_splits\", n_splits)\n",
    "\n",
    "    # metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"cape\", cape)\n",
    "\n",
    "    # artifacts\n",
    "    mlflow.sklearn.log_model(knn_reg2, \"knn\")\n",
    "    # mlflow.log_artifact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred = np.concatenate((predictions, np.array(y_test))).reshape(len(y_test),2)\n",
    "df_real_pred =  pd.DataFrame(data=real_pred,\n",
    "                             index=X_test.Time,\n",
    "                             columns=['pred-production','real-production'])\n",
    "df_real_pred.iplot(kind='scatter', filename='cufflinks/cf-simple-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_neighbors = 50\n",
    "list(range(1, max_n_neighbors, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)\n",
    "<a id=\"svm\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train.copy()\n",
    "X_test_2 = X_test.copy()\n",
    "y_train_2 = y_train.copy()\n",
    "y_test_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Pre-process pipeline #####\n",
    "for k_best_features in range(1,10):\n",
    "    print('------- k_best_features = {} ------'.format(k_best_features))\n",
    "    drop_lst = ['ID','Time','U','V']\n",
    "    pre_process = ColumnTransformer(remainder = 'passthrough',\n",
    "                                    transformers = [(\n",
    "                                        'drop_columns', 'drop', drop_lst)\n",
    "                                    ])\n",
    "\n",
    "    tt = Pipeline(steps=[\n",
    "        ('powertransformer', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
    "        # ('normalization', MinMaxScaler(feature_range=(0, 1))) \n",
    "        # ('standard_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    prepare_data_pipeline = Pipeline(steps=[\n",
    "        ('attr_adder', dtr.NewFeaturesAdder(add_time_feat=True, add_cycl_feat=False, add_inv_T=False)), \n",
    "        ('pre_processing', pre_process),\n",
    "        ('powertransformer', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
    "        # ('normalization', MinMaxScaler(feature_range=(0, 1)),\n",
    "        # ('standard_scaler', StandardScaler())    \n",
    "    ])\n",
    "\n",
    "    X_train_pped = prepare_data_pipeline.fit_transform(X_train_2)\n",
    "    X_test_pped = prepare_data_pipeline.transform(X_test_2)\n",
    "\n",
    "    feature_sel = True\n",
    "    feature_names = X_train_2.drop(drop_lst, axis=1).columns\n",
    "\n",
    "    # Feature selection \n",
    "    if feature_sel: \n",
    "        ## using Mutual Information\n",
    "        selec_k_best = SelectKBest(mutual_info_regression, k=k_best_features)\n",
    "        selec_k_best.fit(X_train_pped, y_train_2)\n",
    "        X_train_pped = selec_k_best.transform(X_train_pped)\n",
    "        X_test_pped = selec_k_best.transform(X_test_pped)\n",
    "\n",
    "        mask =selec_k_best.get_support() #list of booleans\n",
    "        selected_feat = [] \n",
    "\n",
    "        for bool, feature in zip(mask, feature_names):\n",
    "            if bool:\n",
    "                selected_feat.append(feature)  \n",
    "\n",
    "    # make scorers\n",
    "    cape_scorer = make_scorer(metric.get_cape, greater_is_better=False)\n",
    "\n",
    "    param_grid = {\n",
    "        'kernel': ('linear', 'rbf','poly'), \n",
    "        'C':[0.01, 1, 0.1, 10, 100],\n",
    "        'gamma': [0.00001, 0.001, 1],\n",
    "        'epsilon':[0.1,0.3,0.5]\n",
    "    }\n",
    "\n",
    "    svm_reg = SVR()\n",
    "    n_splits=9\n",
    "    grid_search_svm = GridSearchCV(\n",
    "        svm_reg, \n",
    "        param_grid, \n",
    "        cv= TimeSeriesSplit(n_splits),\n",
    "        scoring=cape_scorer,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search_svm.fit(X_train_pped, y_train_2)\n",
    "\n",
    "    experiment_name = 'WF1: SVM'\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        svm_reg2 = SVR(kernel = grid_search_svm.best_params_['kernel'],\n",
    "                       C = grid_search_svm.best_params_['C'],\n",
    "                       gamma = grid_search_svm.best_params_['gamma'],\n",
    "                       epsilon = 0.1)\n",
    "\n",
    "        ttreg = TransformedTargetRegressor(regressor=svm_reg2, transformer=tt, check_inverse=False)\n",
    "\n",
    "        ttreg.fit(X_train_pped, y_train_2)\n",
    "        # svm_reg2.fit(X_train_pped, y_train_2)\n",
    "\n",
    "        # learning curves\n",
    "        train_size = np.linspace(0.1, 1.0, 7)\n",
    "        train_sizes, train_scores, validation_scores = learning_curve(estimator = ttreg,\n",
    "                                                                      X = X_train_pped,\n",
    "                                                                      y = y_train_2, \n",
    "                                                                      train_sizes = train_size,\n",
    "                                                                      scoring = cape_scorer)\n",
    "\n",
    "        train_scores_mean = -train_scores.mean(axis = 1)\n",
    "        validation_scores_mean = -validation_scores.mean(axis = 1)\n",
    "\n",
    "        plt.style.use('seaborn')\n",
    "        plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n",
    "        plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')\n",
    "        plt.ylabel('CAPE', fontsize = 14)\n",
    "        plt.xlabel('Training set size', fontsize = 14)\n",
    "        plt.title('Learning curves for SVM', fontsize = 18, y = 1.03)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # Validation curves\n",
    "        param_range = list(range(0,30,2))\n",
    "        train_scores, test_scores = validation_curve(SVR(kernel = grid_search_svm.best_params_['kernel'],\n",
    "                                                         gamma = grid_search_svm.best_params_['gamma'],\n",
    "                                                         epsilon = grid_search_svm.best_params_['epsilon']),\n",
    "                                                     X_train_pped, y_train_2, \"C\",param_range, cv=5)\n",
    "\n",
    "        train_mean = np.mean(train_scores, axis=1)\n",
    "        train_std = np.std(train_scores, axis=1)\n",
    "        test_mean = np.mean(test_scores, axis=1)\n",
    "        test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "        plt.style.use('seaborn')\n",
    "        plt.plot(param_range, train_mean, label=\"training accuracy\")\n",
    "        plt.plot(param_range, test_mean, linestyle=\"--\", label=\"validation accuracy\")\n",
    "        plt.ylabel('Accuracy', fontsize = 14)\n",
    "        plt.xlabel('C', fontsize = 14)\n",
    "        plt.title('Validation curve for SVM', fontsize = 18, y = 1.03)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # Testing\n",
    "        predictions = ttreg.predict(X_test_pped)\n",
    "        #predictions = svm_reg2.predict(X_test_pped)\n",
    "\n",
    "        # Building prediction matrix (ID,Production)\n",
    "        pred_matrix = np.stack((np.array(y_test_2.index.to_series()).astype(int), predictions), axis=-1)\n",
    "        df_pred = pd.DataFrame(data=pred_matrix.reshape(-1,2), columns=['ID','Production'])\n",
    "\n",
    "        print('Best CV score:', -grid_search_svm.best_score_)\n",
    "        print('Test CAPE: ', metric.get_cape(y_test_2, predictions))\n",
    "        print('Test rmse: ', np.sqrt(mean_squared_error(y_test_2, predictions)))\n",
    "        print('Test R2: ', r2_score(y_test_2, predictions))\n",
    "\n",
    "        ### MLFlow logging ####\n",
    "        (rmse, mae, r2, cape) = eval_metrics(y_test_2, predictions)\n",
    "\n",
    "        mlflow.set_tag(\"grid_searh_best_params\", grid_search_svm.best_params_)\n",
    "\n",
    "        # pre-processing\n",
    "        mlflow.log_param(\"clean_outliers\", clean_outliers)\n",
    "        mlflow.log_param(\"feature_selection\", feature_sel)\n",
    "        mlflow.log_param(\"selected_features\", selected_feat)\n",
    "        mlflow.log_param(\"k_best_features\", k_best_features)\n",
    "\n",
    "        # grid search parameters\n",
    "        mlflow.log_param(\"kernel\", param_grid.get(\"kernel\"))\n",
    "        mlflow.log_param(\"C\", param_grid.get(\"C\"))\n",
    "        mlflow.log_param(\"gamma\", param_grid.get(\"gamma\"))\n",
    "        mlflow.log_param(\"epsilon\", param_grid.get(\"epsilon\"))\n",
    "        mlflow.log_param(\"CV_splits\", n_splits)\n",
    "\n",
    "        # metrics\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"cape\", cape)\n",
    "\n",
    "        # artifacts\n",
    "        mlflow.sklearn.log_model(ttreg, \"svm\")\n",
    "        # mlflow.log_artifact()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "<a id=\"RF\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train.copy()\n",
    "X_test_2 = X_test.copy()\n",
    "y_train_2 = y_train.copy()\n",
    "y_test_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "for k_best_features in range(1,10):\n",
    "    print('------- k_best_features = {} ------'.format(k_best_features))\n",
    "    \n",
    "    drop_lst = ['ID','Time','U','V','month','hour','w_dir']\n",
    "    pre_process = ColumnTransformer(remainder = 'passthrough',\n",
    "                                    transformers = [(\n",
    "                                        'drop_columns', 'drop', drop_lst)\n",
    "                                    ])\n",
    "    \n",
    "    # tt = Pipeline(steps=[\n",
    "    #     ('powertransformer', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
    "    #     ('normalization', MinMaxScaler(feature_range=(0, 1))),\n",
    "    #     ('standard_scaler', StandardScaler())\n",
    "    # ])\n",
    "    \n",
    "    prepare_data_pipeline = Pipeline(steps=[\n",
    "        ('attr_adder', dtr.NewFeaturesAdder(add_time_feat=True, add_cycl_feat=True, add_inv_T=False)), \n",
    "        ('pre_processing', pre_process)\n",
    "        # ('powertransformer', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
    "        # ('normalization', MinMaxScaler(feature_range=(0, 1)),\n",
    "        # ('standard_scaler', StandardScaler())    \n",
    "    ])\n",
    "    \n",
    "    X_train_pped = prepare_data_pipeline.fit_transform(X_train_2)\n",
    "    X_test_pped = prepare_data_pipeline.transform(X_test_2)\n",
    "    \n",
    "    feature_sel = True\n",
    "    feature_names = X_train_2.drop(drop_lst, axis=1).columns\n",
    "    \n",
    "    # Feature selection \n",
    "    if feature_sel: \n",
    "        ## using Mutual Information\n",
    "        selec_k_best = SelectKBest(mutual_info_regression, k=k_best_features)\n",
    "        selec_k_best.fit(X_train_pped, y_train_2)\n",
    "        X_train_pped = selec_k_best.transform(X_train_pped)\n",
    "        X_test_pped = selec_k_best.transform(X_test_pped)\n",
    "    \n",
    "        mask =selec_k_best.get_support() #list of booleans\n",
    "        selected_feat = [] \n",
    "    \n",
    "        for bool, feature in zip(mask, feature_names):\n",
    "            if bool:\n",
    "                selected_feat.append(feature)  \n",
    "    \n",
    "    # make scorers\n",
    "    cape_scorer = make_scorer(metric.get_cape, greater_is_better=False)\n",
    "    \n",
    "    # hyperparameters\n",
    "    # n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 5)]\n",
    "    # max_features = ['auto', 'sqrt']\n",
    "    # m# ax_depth = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "    # max_depth.append(None)\n",
    "    # min_samples_split = [5, 10, 15, 20]\n",
    "    # min_samples_leaf = [1, 2, 4]\n",
    "    # bootstrap = [True, False]\n",
    "    \n",
    "    # Create the random grid\n",
    "    # random_grid = {'n_estimators': n_estimators,\n",
    "    #                'max_features': max_features,\n",
    "    #                'max_depth': max_depth,\n",
    "    #                'min_samples_split': min_samples_split,\n",
    "    #                'min_samples_leaf': min_samples_leaf,\n",
    "    #                'bootstrap': bootstrap}\n",
    "    # \n",
    "    # Use the random grid to search for best hyperparameters ranges\n",
    "    # rf = RandomForestRegressor()\n",
    "    # rf_random = RandomizedSearchCV(estimator = rf, \n",
    "    #                                param_distributions = random_grid, \n",
    "    #                                n_iter = 100, cv = 3,\n",
    "    #                                random_state=42, \n",
    "    #                                n_jobs = -1)\n",
    "    # \n",
    "    # rf_random.fit(X_train_pped, y_train_2)\n",
    "    # print(rf_random.best_params_)\n",
    "    \n",
    "    param_grid = {\n",
    "        'n_estimators': [75, 150, 225],\n",
    "        'max_features': ['sqrt', 'log2', 'auto'],\n",
    "        'max_depth': [10, 50, 100],\n",
    "        'min_samples_split': [15, 30, 45],\n",
    "        'min_samples_leaf': [4, 6, 8],\n",
    "    }\n",
    "    \n",
    "    n_splits = 7 \n",
    "    forest_reg = RandomForestRegressor(bootstrap=True, random_state=42)\n",
    "    grid_search = GridSearchCV(\n",
    "        forest_reg, \n",
    "        param_grid, \n",
    "        cv=TimeSeriesSplit(n_splits),\n",
    "        scoring=cape_scorer,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_pped, y_train_2)\n",
    "    \n",
    "    experiment_name = 'WF1: Ranfom Forest'\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        forest_reg2 = RandomForestRegressor(\n",
    "            n_estimators=grid_search.best_params_['n_estimators'],\n",
    "            max_features=grid_search.best_params_['max_features'],\n",
    "            max_depth=grid_search.best_params_['max_depth'],\n",
    "            min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "            min_samples_leaf=grid_search.best_params_['min_samples_leaf']\n",
    "            \n",
    "        )\n",
    "    \n",
    "        # ttreg = TransformedTargetRegressor(regressor=forest_reg2, transformer=tt, check_inverse=False)\n",
    "    \n",
    "        # ttreg.fit(X_train_pped, y_train_2)\n",
    "        forest_reg2.fit(X_train_pped, y_train_2)\n",
    "    \n",
    "        # learning curves\n",
    "        train_size = np.linspace(0.1, 1.0, 7)\n",
    "        train_sizes, train_scores, validation_scores = learning_curve(estimator = forest_reg2,\n",
    "                                                                      X = X_train_pped,\n",
    "                                                                      y = y_train_2, \n",
    "                                                                      train_sizes = train_size,\n",
    "                                                                      scoring = cape_scorer)\n",
    "    \n",
    "        train_scores_mean = -train_scores.mean(axis = 1)\n",
    "        validation_scores_mean = -validation_scores.mean(axis = 1)\n",
    "    \n",
    "        plt.style.use('seaborn')\n",
    "        plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n",
    "        plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')\n",
    "        plt.ylabel('CAPE', fontsize = 14)\n",
    "        plt.xlabel('Training set size', fontsize = 14)\n",
    "        plt.title('Learning curves for RF', fontsize = 18, y = 1.03)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "        # Validation curves\n",
    "        #param_range = list(range(1,400,10))\n",
    "        #train_scores, test_scores = validation_curve(RandomForestRegressor(\n",
    "        #    max_features=grid_search.best_params_['max_features'],\n",
    "        #    max_depth=grid_search.best_params_['max_depth'],\n",
    "        #    min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "        #    min_samples_leaf=grid_search.best_params_['min_samples_leaf']\n",
    "        #), X_train_pped, y_train, \"n_estimators\",param_range, cv=TimeSeriesSplit(n_splits))\n",
    "    #\n",
    "        #train_mean = np.mean(train_scores, axis=1)\n",
    "        #train_std = np.std(train_scores, axis=1)\n",
    "        #test_mean = np.mean(test_scores, axis=1)\n",
    "        #test_std = np.std(test_scores, axis=1)\n",
    "    #\n",
    "        #plt.style.use('seaborn')\n",
    "        #plt.plot(param_range, train_mean, label=\"training accuracy\")\n",
    "        #plt.plot(param_range, test_mean, linestyle=\"--\", label=\"validation accuracy\")\n",
    "        #plt.ylabel('Accuracy', fontsize = 14)\n",
    "        #plt.xlabel('# estimators', fontsize = 14)\n",
    "        #plt.title('Validation curve for RF', fontsize = 18, y = 1.03)\n",
    "        #plt.legend()\n",
    "        #plt.show()\n",
    "        #plt.close()\n",
    "    \n",
    "        # Testing\n",
    "        # predictions = ttreg.predict(X_test_pped)\n",
    "        predictions = forest_reg2.predict(X_test_pped)\n",
    "    \n",
    "        # Building prediction matrix (ID,Production)\n",
    "        pred_matrix = np.stack((np.array(y_test_2.index.to_series()).astype(int), predictions), axis=-1)\n",
    "        df_pred = pd.DataFrame(data=pred_matrix.reshape(-1,2), columns=['ID','Production'])\n",
    "    \n",
    "        print('Best CV score:', -grid_search.best_score_)\n",
    "        print('Test CAPE: ', metric.get_cape(y_test_2, predictions))\n",
    "        print('Test rmse: ', np.sqrt(mean_squared_error(y_test_2, predictions)))\n",
    "        print('Test R2: ', r2_score(y_test_2, predictions))\n",
    "    \n",
    "        ### MLFlow logging ####\n",
    "        (rmse, mae, r2, cape) = eval_metrics(y_test_2, predictions)\n",
    "    \n",
    "        mlflow.set_tag(\"grid_searh_best_params\", grid_search.best_params_)\n",
    "    \n",
    "        # pre-processing\n",
    "        mlflow.log_param(\"clean_outliers\", clean_outliers)\n",
    "        mlflow.log_param(\"feature_selection\", feature_sel)\n",
    "    \n",
    "        if feature_sel:\n",
    "            mlflow.log_param(\"k_best_features\", k_best_features)\n",
    "            mlflow.log_param(\"selected_features\", selected_feat)\n",
    "    \n",
    "        # grid search parameters\n",
    "        mlflow.log_param(\"n_estimators\", param_grid.get(\"n_estimators\"))\n",
    "        mlflow.log_param(\"max_features\", param_grid.get(\"max_features\"))\n",
    "        mlflow.log_param(\"max_depth\", param_grid.get(\"max_depth\"))\n",
    "        mlflow.log_param(\"min_samples_leaf\", param_grid.get(\"min_samples_leaf\"))\n",
    "        mlflow.log_param(\"min_samples_split\", param_grid.get(\"min_samples_split\"))\n",
    "    \n",
    "    \n",
    "        # metrics\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"cape\", cape)\n",
    "    \n",
    "        # artifacts\n",
    "        mlflow.sklearn.log_model(forest_reg2, \"RF\")\n",
    "        # mlflow.log_artifact()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-6, 6, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network (ANN)\n",
    "<a id=\"ann\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train.copy()\n",
    "X_test_2 = X_test.copy()\n",
    "y_train_2 = y_train.copy()\n",
    "y_test_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons = 10, learning_rate = 3e-3, input_shape=[5]):\n",
    "    import tensorflow as tf \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
    "    \n",
    "    for layer in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "        \n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    optimizer = tf.keras.optimizers.SGD(lr = learning_rate)\n",
    "    model.compile(loss = \"mse\", optimizer = optimizer)\n",
    "    \n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Feature engineering pipeline #####\n",
    "feat_adder = dtr.NewFeaturesAdder(add_time_feat=True, add_cycl_feat=True, add_inv_T=True, add_interactions=True)\n",
    "\n",
    "drop_lst = []\n",
    "if feat_adder.get_params().get('add_cycl_feat'):\n",
    "    if feat_adder.get_params().get('add_inv_T'):\n",
    "        drop_lst = [\"ID\", \"Time\", \"U\", \"V\", \"wdir\", \"hour\", \"month\", \"T\"]\n",
    "    else:\n",
    "        drop_lst = [\"ID\", \"Time\", \"U\", \"V\", \"wdir\", \"hour\", \"month\"]\n",
    "else:\n",
    "    if feat_adder.get_params().get('add_inv_T'):\n",
    "        drop_lst = [\"ID\", \"Time\", \"U\", \"V\", \"T\"]\n",
    "    else:\n",
    "        drop_lst = [\"ID\", \"Time\", \"U\", \"V\"]\n",
    "\n",
    "pre_process = ColumnTransformer(remainder = 'passthrough',\n",
    "                                transformers = [(\n",
    "                                    'drop_columns', 'drop', drop_lst)\n",
    "                                ])\n",
    "\n",
    "\n",
    "feat_eng_pipeline = Pipeline(steps=[\n",
    "    ('attr_adder', feat_adder), \n",
    "    ('pre_processing', pre_process),\n",
    "    ('powertransformer', PowerTransformer(method='yeo-johnson', standardize=True)),   \n",
    "])\n",
    "\n",
    "\n",
    "X_train_pped = feat_eng_pipeline.fit_transform(X_train_2)\n",
    "X_test_pped = feat_eng_pipeline.transform(X_test_2)\n",
    "\n",
    "#### \n",
    "# Feature selection\n",
    "feature_names = X_train_2.drop(drop_lst, axis=1).columns\n",
    "selec_k_best = SelectKBest(mutual_info_regression, k=1)        \n",
    "\n",
    "# make scorers\n",
    "cape_scorer = make_scorer(metric.get_cape, greater_is_better=False)\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(\n",
    "    build_fn=build_model, epochs=10, batch_size=3)\n",
    "\n",
    "\n",
    "#knn_reg = KNeighborsRegressor()\n",
    "pipeline = Pipeline([(\"univariate_sel\", selec_k_best), (\"ann\", keras_reg)])\n",
    "\n",
    "# KNN model\n",
    "param_grid = {\n",
    "    'ann__n_hidden': [1],\n",
    "    'ann__n_neurons':[20, 30],\n",
    "    'ann__learning_rate':[3e-3],\n",
    "    'ann__input_shape':[8],\n",
    "    'univariate_sel__k': [8] }\n",
    "\n",
    "n_splits=7\n",
    "tscv = TimeSeriesSplit(n_splits)\n",
    "scoring = {'RMSE': 'neg_root_mean_squared_error', 'MAE': 'neg_mean_absolute_error', 'R2':'r2' , 'CAPE': cape_scorer}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid, \n",
    "    scoring = scoring,\n",
    "    refit='CAPE',\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "gcv = grid_search.fit(X_train_pped, y_train_2.to_numpy())\n",
    "\n",
    "experiment_name = 'WF1: ANN'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Feature selection with the best k value obtanined in Grid Search\n",
    "    selec_k_best = SelectKBest(mutual_info_regression, k=grid_search.best_params_['univariate_sel__k'])\n",
    "    selec_k_best.fit(X_train_pped, y_train_2)\n",
    "    X_train_pped = selec_k_best.transform(X_train_pped)\n",
    "    X_test_pped = selec_k_best.transform(X_test_pped)\n",
    "    \n",
    "    mask =selec_k_best.get_support() #list of booleans\n",
    "    selected_feat = [] \n",
    "\n",
    "    for bool, feature in zip(mask, feature_names):\n",
    "        if bool:\n",
    "            selected_feat.append(feature)                                                             \n",
    "\n",
    "    # re-training with the best model parameters\n",
    "    best_model = gcv.best_estimator_.named_steps.get('ann').model\n",
    "    history = best_model.fit(X_train_pped, y_train_2.to_numpy(), epochs=100)\n",
    "    \n",
    "    # plotting learning curves\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0.4, 0.6)\n",
    "    plt.show\n",
    "\n",
    "    # evaluate on test set\n",
    "    # mse_test = best_model.evaluate(X_test_pped, y_test_2.to_numpy().reshape(-1,1))\n",
    "\n",
    "    # predict\n",
    "    predictions = best_model.predict(X_test_pped)\n",
    "\n",
    "    # Building prediction matrix (ID,Production)\n",
    "    pred_matrix = np.stack((np.array(y_test_2.index.to_series()).reshape(-1,1), predictions), axis=-1)\n",
    "    df_pred = pd.DataFrame(data=pred_matrix.reshape(-1,2), columns=['ID','Production'])\n",
    "\n",
    "    print('Test CAPE: ', metric.get_cape(y_test_2.to_numpy().reshape(-1), predictions.reshape(-1)))\n",
    "    print('Test rmse: ', np.sqrt(mean_squared_error(y_test_2, predictions)))\n",
    "    print('Test R2: ', r2_score(y_test_2, predictions))\n",
    "\n",
    "    ### MLFlow logging ####\n",
    "    (rmse, mae, r2, cape) = eval_metrics(y_test_2.to_numpy().reshape(-1), predictions.reshape(-1))\n",
    "\n",
    "    mlflow.set_tag(\"grid_searh_best_params\", grid_search.best_params_)\n",
    "\n",
    "    # pre-processing\n",
    "    mlflow.log_param(\"clean_outliers\", clean_outliers)\n",
    "    mlflow.log_param(\"selected_features\", selected_feat)\n",
    "    # mlflow.log_param(\"k_best_features\", k_bests)\n",
    "\n",
    "    # grid search parameters\n",
    "    mlflow.log_param(\"n_hidden\", param_grid.get(\"ann_n_hidden\"))\n",
    "    mlflow.log_param(\"n_neuron\", param_grid.get(\"ann_n_neuron\"))\n",
    "    mlflow.log_param(\"learning_rate\", param_grid.get(\"ann_learning_rate\"))\n",
    "\n",
    "    # metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"cape\", cape)\n",
    "\n",
    "    # artifacts\n",
    "    # mlflow.sklearn.log_model(best_model, \"ANN\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind Farm 3: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = context.catalog.load(\"X_test_expanded_WF2\")\n",
    "y_test = context.catalog.load(\"y_test_WF2\")\n",
    "predictions = context.catalog.load(\"pred_knn_WF2\")\n",
    "pred = pd.DataFrame(predictions,columns=['predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = pd.DataFrame(columns=['wspeed','real_prod','pred_prod'])\n",
    "df['wspeed'] = X_test['wspeed']\n",
    "df['real_prod'] = y_test[0]\n",
    "df['pred_prod'] = pred['predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
